{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370fa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "# Math Libraries\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for data visualization\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns \n",
    "from sympy import var, plot_implicit\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LogisticRegression # Importing Logistic Model\n",
    "from sklearn.model_selection import train_test_split # Train Test Split\n",
    "from sklearn.preprocessing import MinMaxScaler # Data normalizer Min Max Scale\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error # Calculate the accuracy\n",
    "\n",
    "# Loading Bar\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Convex Hull\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d, Delaunay\n",
    "from numpy.linalg import det\n",
    "from scipy.stats import dirichlet\n",
    "import scipy.stats as sts\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy import stats as st\n",
    "from scipy.optimize import fmin_tnc\n",
    "\n",
    "# Supress warnings\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2e13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "adult_folder = pd.read_csv('adult.csv') # Loading Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49bc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adult_Data_Clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  # Changing collumn names for convenience\n",
    "  df.rename(columns={'capital-gain': 'gain', 'capital-loss': 'loss', 'native-country': 'country',\n",
    "                    'hours-per-week': 'hours','marital-status': 'marital'}, inplace=True)\n",
    "  \n",
    "  # Finding not known data\n",
    "  df['country'] = df['country'].replace('?',np.nan)\n",
    "  df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "  df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "  \n",
    "  # Dropping not known data\n",
    "  df.dropna(how='any',inplace=True)\n",
    "\n",
    "  # Normalizing numerical features\n",
    "  numerical = ['age', 'fnlwgt', 'educational-num', 'gain', 'loss', 'hours']\n",
    "  scaler = MinMaxScaler()\n",
    "  df[numerical] = scaler.fit_transform(df[numerical])  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bd75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dataset = Adult_Data_Clean(adult_folder)\n",
    "\n",
    "# Separating label (income) from the rest of the data and making income binary\n",
    "income_raw = adult_dataset['income'].tolist()\n",
    "adult_dataset = adult_dataset.drop(['income'], axis=1)\n",
    "income = pd.Series(income_raw).astype('category').cat.codes.tolist()\n",
    "adult_dataset.drop(adult_dataset.columns.difference(['age', 'educational-num', 'gender', 'loss', 'hours']), 1, inplace=True)\n",
    "income = 2*np.array(income) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b9a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding\n",
    "per_adult_encoded = pd.get_dummies(adult_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c7d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(per_adult_encoded, income, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea99914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, qtd_data):\n",
    "    #Predicting\n",
    "    y_test_pred = model.predict(X_test[0:qtd_data])\n",
    "    #y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Getting accuracy for the personalized classifier\n",
    "    #per_train_acc = accuracy_score(Y_train, y_train_pred)\n",
    "    #per_test_acc = accuracy_score(Y_test[0:qtd_data], y_test_pred)\n",
    "    \n",
    "    # L2 score\n",
    "    #l2_train_acc = mean_squared_error(Y_train, y_train_pred)\n",
    "    l2_test_acc = mean_squared_error(Y_test[0:qtd_data], y_test_pred)\n",
    "    \n",
    "    return l2_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741d9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicity(m1, m2):\n",
    "    y_test_pred_1 = m1.predict(X_test)\n",
    "    y_test_pred_2 = m2.predict(X_test)\n",
    "    \n",
    "    return np.mean(np.abs(y_test_pred_1 - y_test_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b62cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theoretical_Rashomon(X_t, center, w, alpha, epsilon):\n",
    "    X = X_t.to_numpy()\n",
    "    Id = np.identity(X.shape[1])\n",
    "    A = (X.T @ X + alpha*Id)/epsilon\n",
    "    v = center - w\n",
    "    a = (v @ A) @ v.T - 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a32bf4",
   "metadata": {},
   "source": [
    "## Sampling in the Convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48df6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from Rashomon set\n",
    "\n",
    "def samp_in_hull(deln, n):\n",
    "    dims = points.shape[-1] #get dim\n",
    "    hull = points[ConvexHull(points).vertices] #get hull\n",
    "    deln = hull[Delaunay(hull).simplices] #get Delunay\n",
    "\n",
    "    vols = np.abs(det(deln[:, :dims, :] - deln[:, dims:, :])) / np.math.factorial(dims) #get areas\n",
    "    sample = np.random.choice(len(vols), size = n, p = vols / vols.sum()) \n",
    "\n",
    "    return np.einsum('ijk, ij -> ik', deln[sample], dirichlet.rvs([1]*(dims + 1), size = n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969aa28f",
   "metadata": {},
   "source": [
    "## Implementing Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fe4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ridge(X, Y, alpha):\n",
    "    return np.linalg.inv(X.T@X + alpha*np.identity(X.shape[1])) @ X.T @ Y\n",
    "\n",
    "def get_ridge_prediction(parameter, X):\n",
    "    return X@parameter\n",
    "\n",
    "def get_ridge_l2_loss(parameter, alpha, X, Y):\n",
    "    fp = Y - X@parameter\n",
    "    n = X.shape[0]\n",
    "    return (np.dot(fp, fp) + alpha * np.dot(parameter, parameter) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008927a5",
   "metadata": {},
   "source": [
    "## Calculating the Rashomon set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de60f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "np_X = X_train.to_numpy()\n",
    "omega_hat = get_ridge(np_X, Y_train, alpha)\n",
    "np_X_test = X_test.to_numpy()\n",
    "\n",
    "pred = get_ridge_prediction(omega_hat, np_X)\n",
    "pred_test = get_ridge_prediction(omega_hat, np_X_test)\n",
    "#np.mean(get_thresholded(pred) == Y_train), np.mean(get_thresholded(pred_test) == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbbe3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [07:52<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "center = omega_hat\n",
    "delta = 0.1 #Size of initial noise\n",
    "step = 0.0001 #step size for each step in an direction\n",
    "samples = 1000 #number of directions\n",
    "qtd_points = X_train.shape[0]\n",
    "epsilon = 0.1 * get_ridge_l2_loss(center, alpha, np_X, Y_train) #Rashomon set size\n",
    "\n",
    "extremes_l = np.zeros((samples, center.size))\n",
    "early_stopping_exploration = 1000\n",
    "for i in tqdm(range(samples)):\n",
    "    #Generationg direction\n",
    "    Z = np.random.normal(loc=0.0, scale=1.0, size=center.size)\n",
    "    Z = Z/np.linalg.norm(Z)\n",
    "    direction = center + delta * Z\n",
    "    #loading model\n",
    "    ct = 1\n",
    "    while (get_ridge_l2_loss(direction, alpha, np_X, Y_train) - get_ridge_l2_loss(omega_hat, alpha, np_X, Y_train)) < epsilon:\n",
    "        extremes_l[i, :] = direction\n",
    "        direction = center + ct*delta*Z\n",
    "        ct += 1\n",
    "        if ct==early_stopping_exploration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77533dee",
   "metadata": {},
   "source": [
    "# Generating the mode ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba83505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholded(pred):\n",
    "    return 2*(pred > 0)*1 - 1\n",
    "\n",
    "def get_mode_prediction(models_in_ensemble, X):\n",
    "    n_models = models_in_ensemble.shape[0]\n",
    "    pred = np.zeros((n_models, X.shape[0]))\n",
    "    for i in range(n_models):\n",
    "        pred[i] = get_thresholded(get_ridge_prediction(models_in_ensemble[i], X))  #geting votes\n",
    "        \n",
    "    return st.mode(pred)[0] #np.mean(pred, axis = 0) \n",
    "\n",
    "# Sampling from Rashomon set after calculating cvx hull and triangulation\n",
    "def samp_in_hull_after(deln, vols, n):\n",
    "    sample = np.random.choice(len(vols), size = n, p = vols / vols.sum())\n",
    "    \n",
    "    return np.einsum('ijk, ij -> ik', deln[sample], dirichlet.rvs([1]*(dims + 1), size = n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f55e7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = extremes_l.shape[-1] #get dim\n",
    "hull = extremes_l[ConvexHull(extremes_l).vertices] #get hull\n",
    "deln = hull[Delaunay(hull).simplices] #get Delunay\n",
    "vols = np.abs(det(deln[:, :dims, :] - deln[:, dims:, :])) / np.math.factorial(dims) #get areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e04bcbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 #number of models in the ensamblex\n",
    "\n",
    "# Getting predictions for the optimal parameter\n",
    "omega_hat = get_ridge(np_X, Y_train, alpha)\n",
    "pred = get_ridge_prediction(omega_hat, np_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7651c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_in_ensemble = samp_in_hull_after(deln, vols, n)\n",
    "ensamble_predition = get_mode_prediction(models_in_ensemble, np_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23a50b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ensamble and the Optimal desagree in: 43 predictions\n",
      "The Ensamble and a random model desagree in: 787 predictions\n",
      "The Optimal and a random model desagree in: 796 predictions\n"
     ]
    }
   ],
   "source": [
    "# selecting a model at random \n",
    "random_model_pred = get_ridge_prediction( samp_in_hull_after(deln, vols, 1)[0], np_X)\n",
    "random_model_t_pred = get_thresholded(random_model_pred)\n",
    "print('The Ensamble and the Optimal desagree in: ' + str(np.sum(ensamble_predition != get_thresholded(pred))) + ' predictions')\n",
    "print('The Ensamble and a random model desagree in: ' + str(np.sum(ensamble_predition != random_model_t_pred)) + ' predictions')\n",
    "print('The Optimal and a random model desagree in: ' + str(np.sum(get_thresholded(pred) != random_model_t_pred)) + ' predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131f21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Ensamble model is: 0.7955862190968997\n",
      "The accuracy of the Optimal model is: 0.7951881827429127\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the Ensamble model is: ' + str(np.mean(ensamble_predition[0] == Y_train)))\n",
    "print('The accuracy of the Optimal model is: ' + str(np.mean(get_thresholded(pred) == Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da98a618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the Ensamble model is: 0.7932422272345319\n",
      "The test accuracy of the Optimal model is: 0.792888417142099\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy of the Ensamble model is: ' + str(np.mean(get_mode_prediction(models_in_ensemble, X_test)[0] == Y_test)))\n",
    "print('The test accuracy of the Optimal model is: ' + str(np.mean(get_thresholded(get_ridge_prediction(omega_hat, X_test)) == Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec046940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [01:26<00:00, 23.17it/s]\n"
     ]
    }
   ],
   "source": [
    "montecarlo_tries = 2000\n",
    "avg_ensamble_disagreement = 0\n",
    "avg_optimal_disagreement = 0\n",
    "n_range= np.array([5000])\n",
    "n_size = len(n_range)\n",
    "acc_ensembles = np.zeros(n_size)\n",
    "disagreements_difference = np.zeros(n_size)\n",
    "\n",
    "for j in range(n_size):\n",
    "    avg_ensamble_disagreement = 0\n",
    "    avg_optimal_disagreement = 0\n",
    "    \n",
    "    models_in_ensemble = samp_in_hull_after(deln, vols, n_range[j])\n",
    "    ensamble_predition = get_mode_prediction(models_in_ensemble, np_X)\n",
    "    \n",
    "    for i in tqdm(range(montecarlo_tries)):    \n",
    "        random_model_pred = get_ridge_prediction(samp_in_hull_after(deln, vols, 1)[0], np_X)\n",
    "        random_model_t_pred = get_thresholded(random_model_pred)\n",
    "        \n",
    "        avg_ensamble_disagreement += np.sum(ensamble_predition != random_model_t_pred)\n",
    "        avg_optimal_disagreement += np.sum(get_thresholded(pred) != random_model_t_pred)\n",
    "        \n",
    "        #print(np.sum(ensamble_predition != random_model_t_pred) - np.sum(get_thresholded(pred) != random_model_t_pred))\n",
    "    \n",
    "        disagreements_difference[j] = - avg_ensamble_disagreement/montecarlo_tries + avg_optimal_disagreement/montecarlo_tries\n",
    "        acc_ensembles[j] = np.mean(ensamble_predition == Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed2647de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.203]), array([0.79549777]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreements_difference, acc_ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd324b59",
   "metadata": {},
   "source": [
    "## Ploting qtd. models in the ensamble vs consistency (avarage L1 dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed0dfae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fairness Rashomon level trade-off')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_range, acc_ensembles, color = 'black')\n",
    "# plt.xlim([0,0.2])\n",
    "# plt.ylim([0, 15])\n",
    "plt.xlabel(r'Rashomon level ($\\epsilon$)')\n",
    "plt.ylabel(r'Fairness Gain ($PL(h_{fair}) - PL(h_{optimal})$)')\n",
    "plt.title('Fairness Rashomon level trade-off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629948b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ns, ensamble_consistances, color = 'black')\n",
    "plt.plot(ns, optimal_consistances, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ensamble_consistances < optimal_consistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ns, prob_consistences, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d071b93",
   "metadata": {},
   "source": [
    "# Compas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(name='adult'):\n",
    "    #% Processing for COMPAS\n",
    "    if name == 'compas':\n",
    "        file = 'compas-scores-two-years.csv'\n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        aux = df\n",
    "        \n",
    "        # select features for analysis\n",
    "        df = df[['age', 'c_charge_degree', 'race',  'sex', 'priors_count', \n",
    "                   'days_b_screening_arrest',  'is_recid',  'c_jail_in', 'c_jail_out', 'juv_fel_count']]\n",
    "        \n",
    "        # drop missing/bad features (following ProPublica's analysis)\n",
    "        # ix is the index of variables we want to keep.\n",
    "\n",
    "        # Remove entries with inconsistent arrest information.\n",
    "        ix = df['days_b_screening_arrest'] <= 30\n",
    "        ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "\n",
    "        # remove entries entries where compas case could not be found.\n",
    "        ix = (df['is_recid'] != -1) & ix\n",
    "\n",
    "        # remove traffic offenses.\n",
    "        ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "\n",
    "\n",
    "        # trim dataset\n",
    "        df = df.loc[ix,:]\n",
    "\n",
    "        # create new attribute \"length of stay\" with total jail time.\n",
    "        df['length_of_stay'] = (pd.to_datetime(df['c_jail_out'])-pd.to_datetime(df['c_jail_in'])).apply(lambda x: x.days)\n",
    "        \n",
    "        # drop 'c_jail_in' and 'c_jail_out'\n",
    "        # drop columns that won't be used\n",
    "        dropCol = ['c_jail_in', 'c_jail_out','days_b_screening_arrest']\n",
    "        df.drop(dropCol,inplace=True,axis=1)\n",
    "        \n",
    "        # rename columns 'sex' to 'gender'\n",
    "        df.rename(index=str, columns={\"sex\": \"gender\"},inplace=True)\n",
    "        \n",
    "        # binarize degree charged\n",
    "        # Misd. = -1, Felony = 1\n",
    "        df.loc[:,'c_charge_degree'] = df['c_charge_degree'].apply(lambda x: 1 if x=='F' else -1)\n",
    "               \n",
    "        # reset index\n",
    "        df.reset_index(inplace=True,drop=True)\n",
    "        # Normalizing numerical features\n",
    "        numerical = ['age', 'priors_count', 'length_of_stay']\n",
    "        scaler = MinMaxScaler()\n",
    "        df[numerical] = scaler.fit_transform(df[numerical])  \n",
    "        \n",
    "    # TODO: add other datasets here\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef751b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_dataset =  load_data('compas')\n",
    "recid = compas_dataset['is_recid'].to_numpy()\n",
    "recid = 2*recid - 1\n",
    "compas_dataset = compas_dataset.drop(['race', 'is_recid'], axis = 1)\n",
    "# One-Hot encoding\n",
    "per_compas_dataset = pd.get_dummies(compas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ba073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "# Spliting dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(per_compas_dataset, recid, test_size = 0.7, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X = X_train.to_numpy()\n",
    "\n",
    "omega_hat = get_ridge(np_X, Y_train, alpha)\n",
    "pred = get_ridge_prediction(omega_hat, np_X)\n",
    "print('The train accuracy of the optimal is: ' + str(np.mean(get_thresholded(pred) ==  Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = omega_hat\n",
    "delta = 0.0001 #Size of initial noise\n",
    "step = 0.0001 #step size for each step in an direction\n",
    "samples = 1000 #number of directions\n",
    "epsilon = 1*10**(-1) #Rashomon set size\n",
    "\n",
    "extremes_l = np.zeros((samples, center.size))\n",
    "early_stopping_exploration = 1000\n",
    "for i in tqdm(range(samples)):\n",
    "    #Generationg direction\n",
    "    Z = np.random.normal(loc=0.0, scale=1.0, size=center.size)\n",
    "    Z = Z/np.linalg.norm(Z)\n",
    "    direction = center + delta * Z\n",
    "    #loading model\n",
    "    ct = 1\n",
    "    while (get_ridge_l2_loss(direction, alpha, np_X, Y_train) - get_ridge_l2_loss(omega_hat, alpha, np_X, Y_train)) < epsilon:\n",
    "        extremes_l[i, :] = direction\n",
    "        direction = center + ct*delta*Z\n",
    "        ct += 1\n",
    "        if ct==early_stopping_exploration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79088d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = extremes_l.shape[-1] #get dim\n",
    "hull = extremes_l[ConvexHull(extremes_l).vertices] #get hull\n",
    "deln = hull[Delaunay(hull).simplices] #get Delunay\n",
    "vols = np.abs(det(deln[:, :dims, :] - deln[:, dims:, :])) / np.math.factorial(dims) #get areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 #number of models in the ensamblex\n",
    "# Getting predictions for the optimal parameter\n",
    "omega_hat = get_ridge(np_X, Y_train, alpha)\n",
    "pred = get_ridge_prediction(omega_hat, np_X)\n",
    "\n",
    "models_in_ensemble = samp_in_hull_after(deln, vols, n)\n",
    "ensamble_predition = get_mode_prediction(models_in_ensemble, np_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting a model at random \n",
    "random_model_pred = get_ridge_prediction( samp_in_hull_after(deln, vols, 1)[0], np_X)\n",
    "random_model_t_pred = get_thresholded(random_model_pred)\n",
    "print('The Ensamble and the Optimal desagree in: ' + str(np.sum(ensamble_predition != get_thresholded(pred))) + ' predictions')\n",
    "print('The Ensamble and a random model desagree in: ' + str(np.sum(ensamble_predition != random_model_t_pred)) + ' predictions')\n",
    "print('The Optimal and a random model desagree in: ' + str(np.sum(get_thresholded(pred) != random_model_t_pred)) + ' predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy of the Ensamble model is: ' + str(np.mean(ensamble_predition[0] == Y_train)))\n",
    "print('The accuracy of the Optimal model is: ' + str(np.mean(get_thresholded(pred) == Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b09e9",
   "metadata": {},
   "source": [
    "## Label Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fliped(gamma, Y):\n",
    "    tbc_entrie = np.random.uniform(0,1, Y.shape) < gamma\n",
    "    Y[ tbc_entrie ] = -1 * Y[ tbc_entrie ] \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_flip =get_fliped(0.5, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "np_X = X_test.to_numpy()\n",
    "np_X_test = X_test.to_numpy()\n",
    "\n",
    "omega_hat_flip = get_ridge(np_X, Y_train_flip, alpha)\n",
    "pred_flip = get_ridge_prediction(omega_hat_flip, np_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = omega_hat_flip\n",
    "delta = 0.1 #Size of initial noise\n",
    "step = 0.0001 #step size for each step in an direction\n",
    "samples = 1000 #number of directions\n",
    "qtd_points = X_train.shape[0]\n",
    "epsilon = 0.1 * qtd_points #Rashomon set size\n",
    "\n",
    "extremes_flip = np.zeros((samples, center.size))\n",
    "early_stopping_exploration = 1000\n",
    "for i in tqdm(range(samples)):\n",
    "    #Generationg direction\n",
    "    Z = np.random.normal(loc=0.0, scale=1.0, size=center.size)\n",
    "    Z = Z/np.linalg.norm(Z)\n",
    "    direction = center + delta * Z\n",
    "    #loading model\n",
    "    ct = 1\n",
    "    while (get_ridge_l2_loss(direction, alpha, np_X, Y_train_flip) - get_ridge_l2_loss(center, alpha, np_X, Y_train_flip)) < epsilon:\n",
    "        extremes_flip[i, :] = direction\n",
    "        direction = center + ct*delta*Z\n",
    "        ct += 1\n",
    "        if ct==early_stopping_exploration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717777a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = extremes_flip.shape[-1] #get dim\n",
    "hull_flip = extremes_flip[ConvexHull(extremes_flip).vertices] #get hull\n",
    "deln_flip = hull_flip[Delaunay(hull_flip).simplices] #get Delunay\n",
    "vols_flip = np.abs(det(deln_flip[:, :dims, :] - deln_flip[:, dims:, :])) / np.math.factorial(dims) #get areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb139cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4000 #number of models in the ensamblex\n",
    "\n",
    "models_in_ensemble = samp_in_hull_after(deln_flip, vols_flip, n)\n",
    "\n",
    "ensamble_test_predition = get_mode_prediction(models_in_ensemble, np_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa20772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy of the Ensamble model is: ' + str(np.mean(ensamble_test_predition[0] == Y_test)))\n",
    "print('The accuracy of the Optimal model is: ' + str(np.mean(get_thresholded(pred_flip) == Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38fa28",
   "metadata": {},
   "source": [
    "## Plots Label Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "montecarlo_tries = 2\n",
    "prob_flip = np.array([0, 0.01, 0.05, 0.1, 0.5])\n",
    "\n",
    "n_size = len(prob_flip)\n",
    "\n",
    "acc_ensembles_test = np.zeros(n_size)\n",
    "acc_optimal_test = np.zeros(n_size)\n",
    "\n",
    "\n",
    "\n",
    "for j in tqdm(range(n_size)):\n",
    "    avg_acc_ensembles_test = 0\n",
    "    avg_acc_optimal_test = 0\n",
    "    \n",
    "    for i in range(montecarlo_tries): \n",
    "        print(1)\n",
    "        Y_train_flip =get_fliped(prob_flip[j], Y_train) \n",
    "        \n",
    "        omega_hat_flip = get_ridge(np_X, Y_train_flip, alpha)\n",
    "        pred_flip = get_ridge_prediction(omega_hat_flip, np_X_test)\n",
    "        \n",
    "        center = omega_hat_flip\n",
    "        delta = 0.1 #Size of initial noise\n",
    "        samples = 1000 #number of directions\n",
    "        qtd_points = X_train.shape[0]\n",
    "        epsilon = 0.1 * qtd_points #Rashomon set size\n",
    "\n",
    "        extremes_flip = np.zeros((samples, center.size))\n",
    "        early_stopping_exploration = 1000\n",
    "\n",
    "\n",
    "        for i in range(samples):\n",
    "            #Generationg direction\n",
    "            Z = np.random.normal(loc=0.0, scale=1.0, size=center.size)\n",
    "            Z = Z/np.linalg.norm(Z)\n",
    "            direction = center + delta * Z\n",
    "            #loading model\n",
    "            ct = 1\n",
    "            while (get_ridge_l2_loss(direction, alpha, np_X, Y_train_flip) - get_ridge_l2_loss(center, alpha, np_X, Y_train_flip)) < epsilon:\n",
    "                extremes_flip[i, :] = direction\n",
    "                direction = center + ct*delta*Z\n",
    "                ct += 1\n",
    "                if ct==early_stopping_exploration:\n",
    "                    break\n",
    "\n",
    "        dims = extremes_flip.shape[-1] #get dim\n",
    "        hull_flip = extremes_flip[ConvexHull(extremes_flip).vertices] #get hull\n",
    "        deln_flip = hull_flip[Delaunay(hull_flip).simplices] #get Delunay\n",
    "        vols_flip = np.abs(det(deln_flip[:, :dims, :] - deln_flip[:, dims:, :])) / np.math.factorial(dims) #get areas\n",
    "        \n",
    "        \n",
    "        n = 1000 #number of models in the ensamblex\n",
    "        models_in_ensemble = samp_in_hull_after(deln_flip, vols_flip, n)\n",
    "        ensamble_test_predition = get_mode_prediction(models_in_ensemble, np_X_test)\n",
    "\n",
    "        \n",
    "        avg_acc_ensembles_test += np.mean(ensamble_test_predition[0] == Y_test)\n",
    "        avg_acc_optimal_test += np.mean(get_thresholded(pred_flip) == Y_test)\n",
    "    \n",
    "    \n",
    "    acc_ensembles_test[j] = avg_acc_ensembles_test / montecarlo_tries\n",
    "    acc_optimal_test[j] = avg_acc_optimal_test / montecarlo_tries\n",
    "    print(acc_ensembles_test, acc_optimal_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_optimal_test , acc_ensembles_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be759bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
